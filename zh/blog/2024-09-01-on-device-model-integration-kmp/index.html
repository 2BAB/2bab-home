<html lang="zh" dir="ltr">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:title" content="移植 Mediapipe Demo 到 Kotlin Multiplatform (1) LLM Inference" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://2bab.me/zh/blog/2024-09-01-on-device-model-integration-kmp/" />
  <link rel="stylesheet" href="/styles/main.css">
  <link rel="me" href="https://2bab.me/">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.27.0/themes/prism.min.css">
  
  <title>移植 Mediapipe Demo 到 Kotlin Multiplatform (1) LLM Inference | 2BAB&#39;s Blog</title>
  
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NFRNXW3SHS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-NFRNXW3SHS');
</script>

<body>
  
<div>
  <div class="container mx-auto prose py-12 sm:py-24 px-12 sm:px-0">
    <div class="mb-12">
      <a class="no-underline font-bold" href="/zh">2BAB&#39;s Blog</a>
    </div>
    <h1>移植 Mediapipe Demo 到 Kotlin Multiplatform (1) LLM Inference</h1>
    <div class="italic text-gray-500">
      2024/09/01
    </div>
    <div>
      <p>在不久前的厦门和广州 Google I/O Extended 上，我分享了 《On-Device Model 集成（KMP）与用例》。本文将对当时 Demo 进行深入分析，并为后续几篇同类型文章奠定基础。通过本文你将了解到：</p>
<ol>
<li><strong>移植 Mediapipe 的 LLM Inference Android 官方 Demo 到 KMP，支持在 iOS 上运行。</strong> 项目地址：<a href="https://github.com/2BAB/mediapiper">https://github.com/2BAB/mediapiper</a></li>
<li><strong>KMP 两种常见的调用 iOS SDK 的方式</strong>：
<ol>
<li><strong>Kotlin 直接调用 Cocoapods 引入的第三方库。</strong></li>
<li><strong>Kotlin 通过 iOS 工程调用第三方库。</strong></li>
</ol>
</li>
<li><strong>KMP 与多平台依赖注入时的小技巧（基于 Koin）。</strong></li>
<li><strong>On-Device Model 与 LLM 模型 Gemma 1.1 2B 的简单背景。</strong></li>
</ol>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-screenshot.jpg?imageslim" alt=""></p>
<h2 id="on-device-model-%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B" tabindex="-1">On-Device Model 本地模型</h2>
<p>大语言模型（LLM）持续火热了很长一段时间，而今年开始这股风正式吹到了移动端，包括 Google 在内的最新手机与系统均深度集成了此类 On-Device Model 的相关功能。对于 Google 目前的公开战略中，On-Device Model 这块的大语言模型主要分为两个：</p>
<ol>
<li>Gemini Nano：非开源，支持机型较少（某些机型支持特定芯片加速如 Tensor G4），具有强劲的表现。目前可以在桌面平台（Chrome）和部分 Android 手机上使用（Pixel 8/9 和 Samsung S23/24 等）。据报道晚些时候会公开给更多的开发者进行使用和测试。</li>
<li>Gemma：开源，支持所有满足最低要求的机型，同样有不俗的性能表现，与 Nano 使用类似的技术路线进行训练。目前可以在多平台上体验（Android/iOS/Desktop）。据报道晚些时候会提供 Gemma2 版本的 Mediapipe 适配。</li>
</ol>
<p>目前多数开发者尚无法直接基于 Gemini Nano 开发，所以今天的主角便是 Gemma 1 的 2B 版本。想在移动平台上直接使用 Gemma，Google 已给我们提供一个开箱即用的工具：Mediapipe。MediaPipe 是一个跨平台的框架，它封装了一系列预构建的 On-Device 机器学习模型和工具，支持实时的手势识别、面部检测、姿态估计等任务，还可应用于生成图片、聊天机器人等各种应用场景。感兴趣的朋友可以试玩它的 Web 版 <a href="https://mediapipe-studio.webapps.google.com/">Demo</a>，以及相关<a href="https://ai.google.dev/edge/mediapipe/solutions/guide">文档</a>。</p>
<p><img src="https://2bab-images.lastmayday.com/on-device-model-mediapipe-intro.jpg?imageslim" alt=""></p>
<p>而其中的 LLM Inference API（上表第一行），用于运行大语言模型推理的组件，支持 Gemma 2B/7B，Phi-2，Falcon-RW-1B，StableLM-3B 等模型。针对 Gemma 的预转换模型(基于 TensorFlow Lite）可在 Kaggle <a href="https://www.kaggle.com/models/google/gemma/tfLite/gemma-1.1-2b-it-gpu-int4">下载</a>，并在稍后直接放入 Mediapipe 中加载。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-gemma-download.png?imageslim" alt=""></p>
<h2 id="llm-inference-android-sample" tabindex="-1">LLM Inference Android Sample</h2>
<p>Mediapipe 官方的 <a href="https://github.com/google-ai-edge/mediapipe-samples/tree/main/examples/llm_inference/android">LLM Inference Demo</a> 包含了 Android / iOS / Web 前端 等平台。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-demo-android-sample.png?imageslim" alt=""></p>
<p>打开 Android 仓库会发现几个特点：</p>
<ul>
<li><strong>纯 Kotlin</strong> 实现。</li>
<li>UI 是<strong>纯 Jetpack Compose</strong> 实现。</li>
<li>依赖的 LLM Task SDK 已经高度封装，暴露出来的方法仅 3 个。</li>
</ul>
<p>再查看 iOS 的版本：</p>
<ul>
<li>UI 是 SwiftUI 实现，做的事情和 Compose 一模一样，稍微再简化掉一些元素（例如 Topbar 和发送按钮）。</li>
<li>依赖的 LLM Task SDK 已经高度封装，暴露出来的方法一样为 3 个。</li>
</ul>
<p>所以，一个好玩的想法出现了：<strong>Android 版本的这个 Demo 具备移植到 iOS 上的基础；移植可使两边的代码高度高度一致，大幅缩减维护成本，而核心要实现的仅仅是桥接下 iOS 上的 LLM Inference SDK。</strong></p>
<h2 id="kotlin-multiplatform" tabindex="-1">Kotlin Multiplatform</h2>
<p>移植工程所使用的技术叫做 Kotlin Multiplatform（缩写为 <strong>KMP</strong>），它是 Kotlin 团队开发的一种支持跨平台开发的技术，允许开发者使用相同的代码库来构建 Android、iOS、Web 等多个平台的应用程序。通过共享业务逻辑代码，KMP 能显著减少开发时间和维护成本，同时尽量保留每个平台的原生性能和体验。Google 在今年的 I/O 大会上也宣布对 KMP 提供一等的支持，把一些 Android 平台上的库和工具迁移到了多平台，KMP 的开发者可以方便的使用它到 iOS 等其他平台。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-kmp-1.jpg?imageslim" alt="">
<img src="https://2bab-images.lastmayday.com/202408-on-device-model-kmp-2.jpg?imageslim" alt=""></p>
<p>尽管 Mediapipe 也支持多个平台，但我们这次主要聚焦在 Android 和 iOS。一方面更贴近现实，各行各业使用 KMP 的公司的用例更多在移动端上；另外一方面也更方便对标其他移动端开发技术栈。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-kmp-3.png?imageslim" alt=""></p>
<h2 id="%E7%A7%BB%E6%A4%8D%E6%B5%81%E7%A8%8B" tabindex="-1">移植流程</h2>
<h3 id="%E5%88%9D%E5%A7%8B%E5%8C%96" tabindex="-1">初始化</h3>
<p>使用 IDEA 或 Android Studio 创建一个 KMP 的基础工程，你可以借助 KMP Wizard 或者第三方 KMP App 的模版。如果你没有 KMP 的相关经验，可以看到它其实就是一个非常类似 Android 工程的结构，只不过这一次我们把 iOS 的壳工程也放到根目录，并且在 app 模块的 <code>build.gradle.kts</code> 内同时配置了 iOS 的相关依赖。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-proj-3.jpg?imageslim" alt=""></p>
<h3 id="%E5%B0%81%E8%A3%85%E5%92%8C%E8%B0%83%E7%94%A8-llm-inference" tabindex="-1">封装和调用 LLM Inference</h3>
<p>我们在 <code>commonMain</code> 中，根据 Mediapipe LLM Task SDK 的特征抽象一个简单的接口，使用 Kotlin 编写，用以满足 Android 和 iOS 两端的需要。该接口取代了原有仓库里的 <code>InferenceModel.kt</code> 类。</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// app/src/commonMain/.../llm/LLMOperator</span><br><span class="token keyword">interface</span> LLMOperator <span class="token punctuation">{</span><br><br>    <span class="token comment">/**<br>     * To load the model into current context.<br>     * @return 1. null if it went well 2. an error message in string<br>     */</span><br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">initModel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> String<span class="token operator">?</span><br><br>    <span class="token keyword">fun</span> <span class="token function">sizeInTokens</span><span class="token punctuation">(</span>text<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> Int<br><br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> String<br><br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> Flow<span class="token operator">&lt;</span>Pair<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token operator">></span><br><br><span class="token punctuation">}</span></code></pre>
<p>在 Android 上面，因为 LLM Task SDK 原先就是 Kotlin 实现的，所以除了初始化加载模型文件，其余的部分基本就是代理原有的 SDK 功能。</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token keyword">class</span> <span class="token function">LLMInferenceAndroidImpl</span><span class="token punctuation">(</span><span class="token keyword">private</span> <span class="token keyword">val</span> ctx<span class="token operator">:</span> Context<span class="token punctuation">)</span><span class="token operator">:</span> LLMOperator <span class="token punctuation">{</span><br><br>    <span class="token keyword">private</span> <span class="token keyword">lateinit</span> <span class="token keyword">var</span> llmInference<span class="token operator">:</span> LlmInference<br>    <span class="token keyword">private</span> <span class="token keyword">val</span> initialized <span class="token operator">=</span> <span class="token function">AtomicBoolean</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span><br>    <span class="token keyword">private</span> <span class="token keyword">val</span> partialResultsFlow <span class="token operator">=</span> MutableSharedFlow<span class="token operator">&lt;</span>Pair<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token operator">></span><span class="token punctuation">(</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">)</span><br><br>    <span class="token keyword">override</span> <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">initModel</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> String<span class="token operator">?</span> <span class="token punctuation">{</span><br>        <span class="token keyword">if</span> <span class="token punctuation">(</span>initialized<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>            <span class="token keyword">return</span> <span class="token keyword">null</span><br>        <span class="token punctuation">}</span><br>        <span class="token keyword">return</span> <span class="token keyword">try</span> <span class="token punctuation">{</span><br>            <span class="token keyword">val</span> modelPath <span class="token operator">=</span> <span class="token operator">..</span><span class="token punctuation">.</span><br>            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token function">File</span><span class="token punctuation">(</span>modelPath<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">exists</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">not</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>                <span class="token keyword">return</span> <span class="token string-literal singleline"><span class="token string">"Model not found at path: </span><span class="token interpolation"><span class="token interpolation-punctuation punctuation">$</span><span class="token expression">modelPath</span></span><span class="token string">"</span></span><br>            <span class="token punctuation">}</span><br>            <span class="token function">loadModel</span><span class="token punctuation">(</span>modelPath<span class="token punctuation">)</span><br>            initialized<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><br>            <span class="token keyword">null</span><br>        <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span>e<span class="token operator">:</span> Exception<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>            e<span class="token punctuation">.</span>message<br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br>    <span class="token keyword">private</span> <span class="token keyword">fun</span> <span class="token function">loadModel</span><span class="token punctuation">(</span>modelPath<span class="token operator">:</span> String<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>        <span class="token keyword">val</span> options <span class="token operator">=</span> LlmInference<span class="token punctuation">.</span>LlmInferenceOptions<span class="token punctuation">.</span><span class="token function">builder</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>            <span class="token punctuation">.</span><span class="token function">setModelPath</span><span class="token punctuation">(</span>modelPath<span class="token punctuation">)</span><br>            <span class="token punctuation">.</span><span class="token function">setMaxTokens</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><br>            <span class="token punctuation">.</span><span class="token function">setResultListener</span> <span class="token punctuation">{</span> partialResult<span class="token punctuation">,</span> done <span class="token operator">-></span><br>                <span class="token comment">// Transforming the listener to flow,</span><br>                <span class="token comment">// making it easy on UI integration.</span><br>                partialResultsFlow<span class="token punctuation">.</span><span class="token function">tryEmit</span><span class="token punctuation">(</span>partialResult <span class="token keyword">to</span> done<span class="token punctuation">)</span><br>            <span class="token punctuation">}</span><br>            <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br><br>        llmInference <span class="token operator">=</span> LlmInference<span class="token punctuation">.</span><span class="token function">createFromOptions</span><span class="token punctuation">(</span>ctx<span class="token punctuation">,</span> options<span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br><br>    <span class="token keyword">override</span> <span class="token keyword">fun</span> <span class="token function">sizeInTokens</span><span class="token punctuation">(</span>text<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> Int <span class="token operator">=</span> llmInference<span class="token punctuation">.</span><span class="token function">sizeInTokens</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><br><br>    <span class="token keyword">override</span> <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> String <span class="token punctuation">{</span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>        <span class="token keyword">return</span> llmInference<span class="token punctuation">.</span><span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br><br>    <span class="token keyword">override</span> <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> Flow<span class="token operator">&lt;</span>Pair<span class="token operator">&lt;</span>String<span class="token punctuation">,</span> Boolean<span class="token operator">></span><span class="token operator">></span> <span class="token punctuation">{</span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>        llmInference<span class="token punctuation">.</span><span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token punctuation">)</span><br>        <span class="token keyword">return</span> partialResultsFlow<span class="token punctuation">.</span><span class="token function">asSharedFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br><br><span class="token punctuation">}</span></code></pre>
<p>而针对 iOS，我们先尝试第一种调用方式：<strong>直接调用 Cocoapods 引入的库</strong>。在 app 模块引入 cocoapods 的插件，同时添加 Mediapipe 的 LLM Task 库：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// app/build.gradle.kts</span><br>plugins <span class="token punctuation">{</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token function">alias</span><span class="token punctuation">(</span>libs<span class="token punctuation">.</span>plugins<span class="token punctuation">.</span>cocoapods<span class="token punctuation">)</span><br><span class="token punctuation">}</span><br>cocoapods <span class="token punctuation">{</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    ios<span class="token punctuation">.</span>deploymentTarget <span class="token operator">=</span> <span class="token string-literal singleline"><span class="token string">"15"</span></span><br><br>    <span class="token function">pod</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">"MediaPipeTasksGenAIC"</span></span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>        version <span class="token operator">=</span> <span class="token string-literal singleline"><span class="token string">"0.10.14"</span></span><br>        extraOpts <span class="token operator">+=</span> <span class="token function">listOf</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">"-compiler-option"</span></span><span class="token punctuation">,</span> <span class="token string-literal singleline"><span class="token string">"-fmodules"</span></span><span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br>    <span class="token function">pod</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">"MediaPipeTasksGenAI"</span></span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>        version <span class="token operator">=</span> <span class="token string-literal singleline"><span class="token string">"0.10.14"</span></span><br>        extraOpts <span class="token operator">+=</span> <span class="token function">listOf</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">"-compiler-option"</span></span><span class="token punctuation">,</span> <span class="token string-literal singleline"><span class="token string">"-fmodules"</span></span><span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre>
<p>注意上面的引入配置中要添加一个编译参数为 <code>-fmodules</code> 才可正常生成 Kotlin 的引用（<a href="https://kotlinlang.org/docs/native-cocoapods-libraries.html#support-for-objective-c-headers-with-import-directives">参考链接</a>）。</p>
<blockquote>
<p>一些 Objective-C 库，尤其是那些作为 Swift 库包装器的库，在它们的头文件中使用了 @import 指令。默认情况下，cinterop 不支持这些指令。要启用对 @import 指令的支持，可以在 pod() 函数的配置块中指定 -fmodules 选项。</p>
</blockquote>
<p>之后，我们在 iosMain 中便可直接 import 相关的库代码，如法炮制 Android 端的代理思路：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// 注意这些 import 是 cocoapods 开头的</span><br><span class="token keyword">import</span> cocoapods<span class="token punctuation">.</span>MediaPipeTasksGenAI<span class="token punctuation">.</span>MPPLLMInference<br><span class="token keyword">import</span> cocoapods<span class="token punctuation">.</span>MediaPipeTasksGenAI<span class="token punctuation">.</span>MPPLLMInferenceOptions<br><span class="token keyword">import</span> platform<span class="token punctuation">.</span>Foundation<span class="token punctuation">.</span>NSBundle<br><span class="token operator">..</span><span class="token punctuation">.</span><br><span class="token keyword">class</span> LLMOperatorIOSImpl<span class="token operator">:</span> LLMOperator <span class="token punctuation">{</span><br><br>    <span class="token keyword">private</span> <span class="token keyword">val</span> inference<span class="token operator">:</span> MPPLLMInference<br>    <br>        <span class="token keyword">init</span> <span class="token punctuation">{</span><br>        <span class="token keyword">val</span> modelPath <span class="token operator">=</span> NSBundle<span class="token punctuation">.</span>mainBundle<span class="token punctuation">.</span><span class="token function">pathForResource</span><span class="token punctuation">(</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token string-literal singleline"><span class="token string">"bin"</span></span><span class="token punctuation">)</span><br><br>        <span class="token keyword">val</span> options <span class="token operator">=</span> <span class="token function">MPPLLMInferenceOptions</span><span class="token punctuation">(</span>modelPath<span class="token operator">!!</span><span class="token punctuation">)</span><br>        options<span class="token punctuation">.</span><span class="token function">setModelPath</span><span class="token punctuation">(</span>modelPath<span class="token operator">!!</span><span class="token punctuation">)</span><br>        options<span class="token punctuation">.</span><span class="token function">setMaxTokens</span><span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">)</span><br>        options<span class="token punctuation">.</span><span class="token function">setTopk</span><span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">)</span><br>        options<span class="token punctuation">.</span><span class="token function">setTemperature</span><span class="token punctuation">(</span><span class="token number">0.8f</span><span class="token punctuation">)</span><br>        options<span class="token punctuation">.</span><span class="token function">setRandomSeed</span><span class="token punctuation">(</span><span class="token number">102</span><span class="token punctuation">)</span><br><br>        <span class="token comment">// NPE was thrown here right after it printed the success initialization message internally.</span><br>        inference <span class="token operator">=</span> <span class="token function">MPPLLMInference</span><span class="token punctuation">(</span>options<span class="token punctuation">,</span> <span class="token keyword">null</span><span class="token punctuation">)</span> <br>    <span class="token punctuation">}</span><br><br>    <span class="token keyword">override</span> <span class="token keyword">fun</span> <span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> String <span class="token punctuation">{</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">}</span><br>    <span class="token keyword">override</span> <span class="token keyword">fun</span> <span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">,</span> <span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token operator">:</span><span class="token operator">..</span><span class="token punctuation">.</span> <span class="token punctuation">{</span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token punctuation">}</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br><span class="token punctuation">}</span></code></pre>
<p>但这回我们没那么幸运，<code>MPPLLMInference</code> 初始化结束的一瞬间有 NPE 抛出。最可能的问题是因为 Kotlin 现在 interop 的目标是 Objective-C，<code>MPPLLMInference</code> 的构造器比 Swift 版本多一个 error 参数，而我们传入的是 null。</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token keyword">constructor</span><span class="token punctuation">(</span><br>  options<span class="token operator">:</span> cocoapods<span class="token punctuation">.</span>MediaPipeTasksGenAI<span class="token punctuation">.</span>MPPLLMInferenceOptions<span class="token punctuation">,</span> <br>  error<span class="token operator">:</span> CPointer<span class="token operator">&lt;</span>ObjCObjectVar<span class="token operator">&lt;</span>platform<span class="token punctuation">.</span>Foundation<span class="token punctuation">.</span>NSError<span class="token operator">?</span><span class="token operator">></span><span class="token operator">></span><span class="token operator">?</span><span class="token punctuation">)</span></code></pre>
<p>尝试了多种指针传入方式后，仍未解决该问题：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// 其中一种尝试</span><br>memScoped <span class="token punctuation">{</span><br>    <span class="token keyword">val</span> pp<span class="token operator">:</span> CPointerVar<span class="token operator">&lt;</span>ObjCObjectVar<span class="token operator">&lt;</span>NSError<span class="token operator">?</span><span class="token operator">></span><span class="token operator">></span> <span class="token operator">=</span> <span class="token function">allocPointerTo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> inference <span class="token operator">=</span> <span class="token function">MPPLLMInference</span><span class="token punctuation">(</span>options<span class="token punctuation">,</span> pp<span class="token punctuation">.</span>value<span class="token punctuation">)</span><br>    Napier<span class="token punctuation">.</span><span class="token function">i</span><span class="token punctuation">(</span>pp<span class="token punctuation">.</span>value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><br><span class="token punctuation">}</span></code></pre>
<p>（后与一位 Kotlin 专家 BennyHuo 探讨后，推测可能是 Interop 目前的支持有限，对 Swift 的代码里 init 方法有 throws 关键字的支持有局限，详情可看 LlmInference 的<a href="https://github.com/google-ai-edge/mediapipe/blob/cdc08d04ee83f36085894e3a24cb61c949f56b14/mediapipe/tasks/ios/genai/inference/sources/LlmInference.swift#L56">源码</a>，以及 Kotlin 的<a href="https://kotlinlang.org/docs/native-objc-interop.html#errors-and-exceptions">文档</a>）</p>
<p>于是只能另辟蹊径采用第二种方案：通过 iOS 工程调用第三方库。</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// 1. 声明一个类似 LLMOperator 的接口但更简单，方便适配 iOS 的 SDK。</span><br><span class="token comment">// app/src/iosMain/.../llm/LLMOperator.kt</span><br><span class="token keyword">interface</span> LLMOperatorSwift <span class="token punctuation">{</span><br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">loadModel</span><span class="token punctuation">(</span>modelName<span class="token operator">:</span> String<span class="token punctuation">)</span><br>    <span class="token keyword">fun</span> <span class="token function">sizeInTokens</span><span class="token punctuation">(</span>text<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> Int<br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span><span class="token operator">:</span> String<br>    <span class="token keyword">suspend</span> <span class="token keyword">fun</span> <span class="token function">generateResponseAsync</span><span class="token punctuation">(</span><br>        inputText<span class="token operator">:</span> String<span class="token punctuation">,</span><br>        progress<span class="token operator">:</span> <span class="token punctuation">(</span>partialResponse<span class="token operator">:</span> String<span class="token punctuation">)</span> <span class="token operator">-></span> Unit<span class="token punctuation">,</span><br>        completion<span class="token operator">:</span> <span class="token punctuation">(</span>completeResponse<span class="token operator">:</span> String<span class="token punctuation">)</span> <span class="token operator">-></span> Unit<br>    <span class="token punctuation">)</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// 2. 在 iOS 工程里实现这个接口</span><br><span class="token comment">// iosApp/iosApp/LLMInferenceDelegate.swift</span><br><span class="token keyword">class</span> LLMOperatorSwiftImpl<span class="token operator">:</span> LLMOperatorSwift <span class="token punctuation">{</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token keyword">var</span> llmInference<span class="token operator">:</span> LlmInference<span class="token operator">?</span><br>    <br>    func <span class="token function">loadModel</span><span class="token punctuation">(</span>modelName<span class="token operator">:</span> String<span class="token punctuation">)</span> async throws <span class="token punctuation">{</span><br>        let path <span class="token operator">=</span> Bundle<span class="token punctuation">.</span>main<span class="token punctuation">.</span><span class="token function">path</span><span class="token punctuation">(</span>forResource<span class="token operator">:</span> modelName<span class="token punctuation">,</span> ofType<span class="token operator">:</span> <span class="token string-literal singleline"><span class="token string">"bin"</span></span><span class="token punctuation">)</span><span class="token operator">!</span><br>        let llmOptions <span class="token operator">=</span>  LlmInference<span class="token punctuation">.</span><span class="token function">Options</span><span class="token punctuation">(</span>modelPath<span class="token operator">:</span> path<span class="token punctuation">)</span><br>        llmOptions<span class="token punctuation">.</span>maxTokens <span class="token operator">=</span> <span class="token number">4096</span><br>        llmOptions<span class="token punctuation">.</span>temperature <span class="token operator">=</span> <span class="token number">0.9</span><br>        <br>        llmInference <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token function">LlmInference</span><span class="token punctuation">(</span>options<span class="token operator">:</span> llmOptions<span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br>    <br>    func <span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">)</span> async throws <span class="token operator">-></span> String <span class="token punctuation">{</span><br>        <span class="token keyword">return</span> <span class="token keyword">try</span> llmInference<span class="token operator">!</span><span class="token punctuation">.</span><span class="token function">generateResponse</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> inputText<span class="token punctuation">)</span><br>    <span class="token punctuation">}</span><br>    <br>    func <span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> String<span class="token punctuation">,</span> progress<span class="token operator">:</span> <span class="token label symbol">@escaping</span> <span class="token punctuation">(</span>String<span class="token punctuation">)</span> <span class="token operator">-></span> Void<span class="token punctuation">,</span> completion<span class="token operator">:</span> <span class="token label symbol">@escaping</span> <span class="token punctuation">(</span>String<span class="token punctuation">)</span> <span class="token operator">-></span> Void<span class="token punctuation">)</span> async throws <span class="token punctuation">{</span><br>        <span class="token keyword">try</span> llmInference<span class="token operator">!</span><span class="token punctuation">.</span><span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>inputText<span class="token operator">:</span> inputText<span class="token punctuation">)</span> <span class="token punctuation">{</span> partialResponse<span class="token punctuation">,</span> error <span class="token keyword">in</span><br>            <span class="token comment">// progress</span><br>            <span class="token keyword">if</span> let e <span class="token operator">=</span> error <span class="token punctuation">{</span><br>                <span class="token function">print</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">"\(self.errorTag) \(e)"</span></span><span class="token punctuation">)</span><br>                <span class="token function">completion</span><span class="token punctuation">(</span>e<span class="token punctuation">.</span>localizedDescription<span class="token punctuation">)</span><br>                <span class="token keyword">return</span><br>            <span class="token punctuation">}</span><br>            <span class="token keyword">if</span> let partial <span class="token operator">=</span> partialResponse <span class="token punctuation">{</span><br>                <span class="token function">progress</span><span class="token punctuation">(</span>partial<span class="token punctuation">)</span><br>            <span class="token punctuation">}</span><br>        <span class="token punctuation">}</span> completion<span class="token operator">:</span> <span class="token punctuation">{</span><br>            <span class="token function">completion</span><span class="token punctuation">(</span><span class="token string-literal singleline"><span class="token string">""</span></span><span class="token punctuation">)</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span>    <br><span class="token punctuation">}</span><br><br><span class="token comment">// 3. iOS 再把代理好的（重点是初始化）类传回给 Kotlin</span><br><span class="token comment">// iosApp/iosApp/iosApp.swift</span><br><span class="token keyword">class</span> AppDelegate<span class="token operator">:</span> UIResponder<span class="token punctuation">,</span> UIApplicationDelegate <span class="token punctuation">{</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    func <span class="token function">application</span><span class="token punctuation">(</span>）<span class="token punctuation">{</span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>        let delegate <span class="token operator">=</span> <span class="token keyword">try</span> <span class="token function">LLMOperatorSwiftImpl</span><span class="token punctuation">(</span><span class="token punctuation">)</span><br>        MainKt<span class="token punctuation">.</span><span class="token function">onStartup</span><span class="token punctuation">(</span>llmInferenceDelegate<span class="token operator">:</span> delegate<span class="token punctuation">)</span>        <br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// 4. 最初 iOS 在 KMP 上的实现细节直接代理给该对象（通过构造器注入）</span><br><span class="token keyword">class</span> <span class="token function">LLMOperatorIOSImpl</span><span class="token punctuation">(</span><br>   <span class="token keyword">private</span> <span class="token keyword">val</span> delegate<span class="token operator">:</span> LLMOperatorSwift<span class="token punctuation">)</span> <span class="token operator">:</span> LLMOperator <span class="token punctuation">{</span>   <br>   <span class="token operator">..</span><span class="token punctuation">.</span><br><span class="token punctuation">}</span></code></pre>
<p>细心的朋友可能已经发现，两端的 Impl 实例需要不同的构造器参数，这个需求一般使用 KMP 的 <code>expect</code> 与 <code>actual</code> 关键字解决。下面的代码中：</p>
<ol>
<li>利用了 expect class 不需要构造器参数声明的特点加了层封装（类似接口）。</li>
<li>利用了 Koin 实现各自平台所需参数的注入，再统一把创建的接口实例注入到 Common 层所需的地方。</li>
</ol>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// Common</span><br><span class="token keyword">expect</span> <span class="token keyword">class</span> LLMOperatorFactory <span class="token punctuation">{</span><br>    <span class="token keyword">fun</span> <span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> LLMOperator<br><span class="token punctuation">}</span><br><span class="token keyword">val</span> sharedModule <span class="token operator">=</span> module <span class="token punctuation">{</span><br>   <span class="token comment">// 从不同的 LLMOperatorFactory 创建出 Common 层所需的 LLMOperator</span><br>	single<span class="token operator">&lt;</span>LLMOperator<span class="token operator">></span> <span class="token punctuation">{</span> <span class="token keyword">get</span><span class="token operator">&lt;</span>LLMOperatorFactory<span class="token operator">></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// Android</span><br><span class="token keyword">actual</span> <span class="token keyword">class</span> <span class="token function">LLMOperatorFactory</span><span class="token punctuation">(</span><span class="token keyword">private</span> <span class="token keyword">val</span> context<span class="token operator">:</span> Context<span class="token punctuation">)</span><span class="token punctuation">{</span><br>    <span class="token keyword">actual</span> <span class="token keyword">fun</span> <span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> LLMOperator <span class="token operator">=</span> <span class="token function">LLMInferenceAndroidImpl</span><span class="token punctuation">(</span>context<span class="token punctuation">)</span><br><span class="token punctuation">}</span><br><span class="token keyword">val</span> androidModule <span class="token operator">=</span> module <span class="token punctuation">{</span><br>    <span class="token comment">// Android 注入 App 的 Context</span><br>    single <span class="token punctuation">{</span> <span class="token function">LLMOperatorFactory</span><span class="token punctuation">(</span><span class="token function">androidContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// iOS</span><br><span class="token keyword">actual</span> <span class="token keyword">class</span> <span class="token function">LLMOperatorFactory</span><span class="token punctuation">(</span><span class="token keyword">private</span> <span class="token keyword">val</span> llmInferenceDelegate<span class="token operator">:</span> LLMOperatorSwift<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token keyword">actual</span> <span class="token keyword">fun</span> <span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> LLMOperator <span class="token operator">=</span> <span class="token function">LLMOperatorIOSImpl</span><span class="token punctuation">(</span>llmInferenceDelegate<span class="token punctuation">)</span><br><span class="token punctuation">}</span><br><br>module <span class="token punctuation">{</span><br>    <span class="token comment">// iOS 注入 onStartup 函数传入的 delegate</span><br>    single <span class="token punctuation">{</span> <span class="token function">LLMOperatorFactory</span><span class="token punctuation">(</span>llmInferenceDelegate<span class="token punctuation">)</span> <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre>
<p>小结：我们通过一个小小的案例，领略到了 <strong>Kotlin</strong> 和 <strong>Swift</strong> 的<strong>深度交互</strong>。还借助 expect / actual 关键字与 Koin 的依赖注入，让整体方案<strong>更流畅和自动化</strong>，达到了在 KMP 的 Common 模块调用 Android 和 iOS Native SDK 的目标。</p>
<h3 id="%E7%A7%BB%E6%A4%8D-ui-%E5%92%8C-viewmodel" tabindex="-1">移植 UI 和 ViewModel</h3>
<p>原项目里的 <code>InferenceMode</code> 已经被上一节的 <code>LLMOperator</code> 所取代，因此我们拷贝除 Activity 的剩下 5 个类：</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-copy-structure.png?imageslim" alt=""></p>
<p>下面我们修改几处代码使 Jetpack Compose 的代码可以方便的迁移到 Compose Multiplatform。</p>
<p>首先是外围的 <code>ViewModel</code>，KMP 版本我在这里使用了 <a href="https://github.com/adrielcafe/voyager">Voyage</a>，因此替换为 <code>ScreenModel</code>。不过官方 ViewModel 的方案也在实验中了，请参考这个<a href="https://www.jetbrains.com/help/kotlin-multiplatform-dev/compose-viewmodel.html">文档</a>。</p>
<pre><code>// Android 版本
class ChatViewModel(
    private val inferenceModel: InferenceModel
) : ViewModel() {...}

// KMP 版本，转换 ViewModel 为 ScreenModel，并修改传入对象
class ChatViewModel(
    private val llmOperator: LLMOperator
) : ScreenModel {...}

</code></pre>
<p>相应的 ViewModel 初始化方式也更改成 ScreenModel 的方法：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// Android 版本</span><br><span class="token annotation builtin">@Composable</span><br><span class="token keyword">internal</span> <span class="token keyword">fun</span> <span class="token function">ChatRoute</span><span class="token punctuation">(</span><br>    chatViewModel<span class="token operator">:</span> ChatViewModel <span class="token operator">=</span> <span class="token function">viewModel</span><span class="token punctuation">(</span><br>        factory <span class="token operator">=</span> ChatViewModel<span class="token punctuation">.</span><span class="token function">getFactory</span><span class="token punctuation">(</span>LocalContext<span class="token punctuation">.</span>current<span class="token punctuation">.</span>applicationContext<span class="token punctuation">)</span><br>    <span class="token punctuation">)</span><br><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token function">ChatScreen</span><span class="token punctuation">(</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token comment">// KMP 版本，改成外部初始化后传入</span><br><span class="token annotation builtin">@Composable</span><br><span class="token keyword">internal</span> <span class="token keyword">fun</span> <span class="token function">ChatRoute</span><span class="token punctuation">(</span><br>    chatViewModel<span class="token operator">:</span> ChatViewModel<br><span class="token punctuation">)</span> <span class="token punctuation">{</span><br><br><span class="token comment">// 此处采用了默认参数注入的方案，便于解耦。</span><br><span class="token comment">// koinInject() 是 Koin 官方提供的针对 Compose </span><br><span class="token comment">// 的 @Composable 函数注入的一个方法。</span><br><span class="token annotation builtin">@Composable</span><br><span class="token keyword">fun</span> <span class="token function">AiScreen</span><span class="token punctuation">(</span>llmOperator<span class="token operator">:</span>LLMOperator <span class="token operator">=</span> <span class="token function">koinInject</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>    <span class="token comment">// 使用 ScreenModel 的 remember 方法</span><br>    <span class="token keyword">val</span> chatViewModel <span class="token operator">=</span> rememberScreenModel <span class="token punctuation">{</span> <span class="token function">ChatViewModel</span><span class="token punctuation">(</span>llmOperator<span class="token punctuation">)</span> <span class="token punctuation">}</span><br>    <span class="token operator">..</span><span class="token punctuation">.</span><br>    Column <span class="token punctuation">{</span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>        <span class="token function">Box</span><span class="token punctuation">(</span><span class="token operator">..</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token punctuation">{</span><br>            <span class="token keyword">if</span> <span class="token punctuation">(</span>showLoading<span class="token punctuation">)</span> <span class="token punctuation">{</span><br>                <span class="token operator">..</span><span class="token punctuation">.</span><br>            <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{</span><br>                <span class="token function">ChatRoute</span><span class="token punctuation">(</span>chatViewModel<span class="token punctuation">)</span><br>            <span class="token punctuation">}</span><br>        <span class="token punctuation">}</span><br>    <span class="token punctuation">}</span><br><span class="token punctuation">}</span></code></pre>
<p>对应的 ViewModel 内部的 LLM 功能调用接口也要进行替换：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// Android 版本</span><br>inferenceModel<span class="token punctuation">.</span><span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>fullPrompt<span class="token punctuation">)</span><br>inferenceModel<span class="token punctuation">.</span>partialResults<br>    <span class="token punctuation">.</span><span class="token function">collectIndexed</span> <span class="token punctuation">{</span> index<span class="token punctuation">,</span> <span class="token punctuation">(</span>partialResult<span class="token punctuation">,</span> done<span class="token punctuation">)</span> <span class="token operator">-></span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token punctuation">}</span><br><br><span class="token comment">// KMP 版本，把 Flow 的返回前置了，兼容了两个平台的 SDK 设计</span><br>llmOperator<span class="token punctuation">.</span><span class="token function">generateResponseAsync</span><span class="token punctuation">(</span>fullPrompt<span class="token punctuation">)</span><br>    <span class="token punctuation">.</span><span class="token function">collectIndexed</span> <span class="token punctuation">{</span> index<span class="token punctuation">,</span> <span class="token punctuation">(</span>partialResult<span class="token punctuation">,</span> done<span class="token punctuation">)</span> <span class="token operator">-></span><br>        <span class="token operator">..</span><span class="token punctuation">.</span><br>    <span class="token punctuation">}</span></code></pre>
<p>然后是 Compose Multiplatform 特定的资源加载方式，把 <code>R</code> 文件替换为 <code>Res</code>：</p>
<pre class="language-kotlin"><code class="language-kotlin"><span class="token comment">// Android 版本</span><br><span class="token function">Text</span><span class="token punctuation">(</span><span class="token function">stringResource</span><span class="token punctuation">(</span>R<span class="token punctuation">.</span>string<span class="token punctuation">.</span>chat_label<span class="token punctuation">)</span><span class="token punctuation">)</span><br><br><span class="token comment">// KMP 版本，该引用是使用插件从 xml 映射而来</span><br><span class="token comment">// (commonMain/composeResources/values/strings.xml)</span><br><span class="token keyword">import</span> mediapiper<span class="token punctuation">.</span>app<span class="token punctuation">.</span>generated<span class="token punctuation">.</span>resources<span class="token punctuation">.</span>chat_label<br><span class="token operator">..</span><span class="token punctuation">.</span><br><span class="token function">Text</span><span class="token punctuation">(</span><span class="token function">stringResource</span><span class="token punctuation">(</span>Res<span class="token punctuation">.</span>string<span class="token punctuation">.</span>chat_label<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<p>至此我们已经完成了 <code>ChatScreen</code> <code>ChatViewModel</code> 的主页面功能迁移。</p>
<p>最后是其他的几个轻微改动：</p>
<ul>
<li><code>LoadingScreen</code> 我们如法炮制传入 <code>LLMOperator</code> 进行初始化（替换原有 <code>InferenceModel</code>）。</li>
<li><code>ChatMessage</code> 只需修改了 UUID 调用的一行 API 到原生实现（Kotlin 2.0.20 后就不需要了）。</li>
<li><code>ChatUiState</code> 则完全不用动。</li>
<li>剩下的就只有整体修改下 Log 库的引用等小细节。</li>
</ul>
<p>小结：倘若略去 Log、R 文件的引用替换以及 import 替换等，<strong>核心的修改其实仅十几行</strong>，便能把<strong>整个 UI 部分也跑起来了</strong>。</p>
<h2 id="%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95" tabindex="-1">简单测试</h2>
<p>那 Gemma 2B 的性能如何，我们看几个简单的例子。此处主要使用三个版本的模型进行测试，模型的定义在 <code>me.xx2bab.mediapiper.llm.LLMOperator</code>（模型在两端部署请参考项目 README）。</p>
<ul>
<li><code>gemma-2b-it-gpu-int4</code></li>
<li><code>gemma-2b-it-cpu-int4</code></li>
<li><code>gemma-2b-it-cpu-int8</code></li>
</ul>
<p>其中：</p>
<ul>
<li>it 指代一种变体，即 Instruction Tuned 模型，更适合聊天用途，因为它们经过微调能更好地理解指令，并生成更准确的回答。</li>
<li>int4/8 指代模型量化，即将模型中的浮点数转换为低精度整数，从而减小模型的大小和计算量以适配小型的本地设备例如手机。当然，模型的精度和回答准确度也会有一些下降。</li>
<li>cpu 和 gpu 指针对的硬件平台，这方便了设备 GPU 较弱甚至没有时可选择 CPU 执行。从下面的测试结果你会发现当前移动设备上 CPU 版本也常常会占优，因为模型规模小、简单对话计算操作也不大，并且 Int 量化也有利于 CPU 的指令执行。</li>
</ul>
<p>首先我们测试一个简单的逻辑：“芦笋是不是一种动物”？可以看到下图的 CPU 版本答案比两个 GPU（iOS 和 Android）更合理。而下一个测试是翻译答案为中文，则是三个尝试都不太行。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-test-1.jpg?imageslim" alt=""></p>
<p>接着我们提高了测试问题的难度，让它执行区分动植物的单词分类：不管是 GPU 或者 CPU 的版本都不错。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-test-2.jpg?imageslim" alt=""></p>
<p>再次提高上个问题，让它用 JSON 的方式输出答案，就出现明显的问题：</p>
<ol>
<li>图1没有输出完整的代码片段，缺少了结尾的三个点 ```。</li>
<li>图二分类错误，把山竹放到动物，植物出现了两次向日葵。</li>
<li>图三同二的错误，但这三次都没有纯输出一个 JSON，实际上还是不够严格执行作为 JSON Responder 的角色。</li>
</ol>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-test-3.jpg?imageslim" alt=""></p>
<p>最后，这其实不是极限，如果我们使用 cpu-int8 的版本，则可以高准确率地解答上面问题。以及，如果把本 Demo 的 iOS 入口代码发送给它分析，也能答的不错。</p>
<p><img src="https://2bab-images.lastmayday.com/202408-on-device-model-test-4.jpg?imageslim" alt=""></p>
<p>Gemma 1 的 2B 版本测试至此，我们发觉其推理效果还有不少进步空间，胜在回复速度不错。而事实上 Gemma 2 的 2B 版本前不久已推出，并且据官方测试其综合水平已超过 GPT 3.5。这意味着在一台小小的手机里，本地的推理已经可以达到一年半前的主流模型效果。但其还未适配到 TFLite（Mediapipe 基于此），之前的新闻稿表示将于近期放出（在 Roadmap 上但无确切日期），大家可以追踪下列 issues 获得最新消息：</p>
<ul>
<li><a href="https://github.com/google-ai-edge/mediapipe/issues/5570">https://github.com/google-ai-edge/mediapipe/issues/5570</a></li>
<li><a href="https://github.com/google-ai-edge/mediapipe/issues/5594">https://github.com/google-ai-edge/mediapipe/issues/5594</a></li>
</ul>
<h2 id="%E6%80%BB%E7%BB%93" tabindex="-1">总结</h2>
<p>实现这个本地聊天 Demo 的迁移和测试，给了我们些一手的经验：</p>
<ul>
<li>LLM 的 On-Device Model 发展非常迅速，而借助 Google 的一系列基础设施可以让第三方 Mobile App 开发者也迅速地集成相关的功能，并跨越 Android 与 iOS 双平台。</li>
<li>观望目前情况综合判断，LLM 的 On-Device Model 有望在今年达到初步可用状态，推理速度已经不错，准确度还有待进一步测试（例如 Gemma 2 的 2B 版本 + Mediapipe）。</li>
<li>遵循 Android 团队目前的策略 “Kotlin First” 并大胆使用 Compose，是颇具前景的——在基础设施完备的情况下，一个聊天的小模块仅寥寥数行修改即可迁移到 iOS。</li>
</ul>

    </div>
    <hr />
      <div class="text-sm text-center">
        评论和交流请发送邮件到 xx2bab@gmail.com
      </div>
      <hr />
     <div class="text-center">
  <img class="w-64 inline-block" src="https://s2.loli.net/2023/05/13/FKYi5STEtmNZd8W.jpg" alt="Wechat Donate QACode" />
  <div class="text-sm">
    通过微信扫描赞赏码赞助此文
  </div>
</div> 
    <footer class="text-sm py-12 text-gray-500 text-center">
  
  <p><a href="/">ENG</a> / <a href="/zh">中文</a></p>
  
  2BAB's Blog since 2014
</footer>
  </div>

</div>



</body>
</html>